 今天整理毕业设计的中国象棋博弈程序，发现对于α-β博弈算法快忘了，所以整理如下：
```c++
//该函数递归调用
double ChessSearch::_AlphaBetaSearch(int _depth,double _alpha,double _beta)
{
	MemoTableNode _ReadMemoNode;
	bool isAlphaFlag=true;
	double goodValue=NEGATIVE_MIN;
	Move   goodMove;
	double value;
	//超时则立即返回
	if((alphaSearchMode==TimeSearch) && (time(NULL)-sg_StartTime >= sg_TimeLimit))
	{
		cout<<"out of time ..........."<<endl;
		return 3.1415926;
	}
	bool ret=readMemoTable(_depth,_alpha,_beta,&_ReadMemoNode);
	if(ret == true)
	{
		return _ReadMemoNode.evaluateValue;
	}
	else
	{
		++totalNodes;
		//小于等于0则直接估值，最后存入置换表、并返回结果
		//	此时是直接估值，所以是准确的值
		//采用静态搜索方式估值
		if(_depth <= 0)
		{
			//value=_QuiescentSearch(_alpha,_beta);
			value=evaluateSituation.evaluate();
			Move _move;_move.from=_move.to=_move.capture=0;
			MemoTableNode _SaveMemoNode;
			_SaveMemoNode.evaluateValue=value;
			_SaveMemoNode.searchDepth=_depth;
			_SaveMemoNode.nodeBestMove=_move;
			_SaveMemoNode.nodeType=allNode;
			saveMemoTable(_SaveMemoNode);
			return value;
		}
		else
		{
			//这里用数组的形式解决走法数组被覆盖的问题，这样启发策略就只能在同一层共享最佳走法
			//参考二维[256][256]对走法投票的方式
			//或者我们可以让这几个走法对象共享一个存储killerMove的内存地址来实现投票的效果
			(chessManMovePtr)->getMoveArrayLen();
			cout<<"depth:"<<_depth<<endl;
			chessManMovePtr[_depth-1].setBestMove(_ReadMemoNode.nodeBestMove);
			chessManMovePtr[_depth-1].setKillerMove(_ReadMemoNode.nodeBestMove);
			chessManMovePtr[_depth-1].genAllMove();
			bool haveSafeMove=false;
			for(int i=0;i<chessManMovePtr[_depth-1].getMoveArrayLen();i++)
			{
				Move _readMove;
				chessManMovePtr[_depth-1].getMove(i,&_readMove);
				if(isSafeMove(_readMove))
					haveSafeMove=true;
				else
					continue;
				moveMaker.makeMove(_readMove);
				//每走一步，变量自赠
				++stepNumber;
				//由于makeMove函数内已经改变走棋方，所以这里的检测自身是否被将死的函数是检测对方
				//检测将死给一个最大值，只会引起本层快速的剪支,并不会快速收敛到跟节点
				if(isCheckDie())
					value=VICTORY_VALUE-stepNumber;
				else
					value=-_AlphaBetaSearch(_depth-1,-_beta,-_alpha);
				moveMaker.unMakeMove();
				--stepNumber;
				if(value > goodValue)
				{
					goodValue=value;
					goodMove=_readMove;
					if(value > _alpha)
					{
						isAlphaFlag=false;
						_alpha=value;
						if(_depth == MaxSearchDepth)
						{
							bestMove=_readMove;
						}
					}
				}
				if(value > _beta)
				{
					MemoTableNode _SaveMemoNode;
					_SaveMemoNode.evaluateValue=_beta;
					_SaveMemoNode.searchDepth=_depth;
					_SaveMemoNode.nodeBestMove=_readMove;
					_SaveMemoNode.nodeType=betaNode;
					saveMemoTable(_SaveMemoNode);
					return _beta;
				}
			}
			if(isAlphaFlag)
			{
				MemoTableNode _SaveMemoNode;
				_SaveMemoNode.evaluateValue=_alpha;
				_SaveMemoNode.searchDepth=_depth;
				_SaveMemoNode.nodeBestMove=goodMove;
				_SaveMemoNode.nodeType=alphaNode;
				saveMemoTable(_SaveMemoNode);
			}
			else
			{
				MemoTableNode _SaveMemoNode;
				_SaveMemoNode.evaluateValue=_alpha;
				_SaveMemoNode.searchDepth=_depth;
				_SaveMemoNode.nodeBestMove=goodMove;
				_SaveMemoNode.nodeType=allNode;
				saveMemoTable(_SaveMemoNode);
			}
			return _alpha;
		}
	}
}
```

这里是从源文件中摘抄的一部分，可以看出我当时的代码风格确实很差。这段函数在基本的α-β算法的基础上添加了：时间限制（防止大量搜索超过预期的时间，如果超时则函数直接返回）；memo（记录重复局面的估值）。
简化的版本如下：

```c++
    int AlphaBeta(int depth, int alpha, int beta) {
    　if (depth == 0) {
    　　return Evaluate();
    　}
    　GenerateLegalMoves();
    　while (MovesLeft()) {
    　　MakeNextMove();
    　　val = -AlphaBeta(depth - 1, -beta, -alpha);
    　　UnmakeMove();
    　　if (val >= beta) {
    　　　return beta;
    　　}
    　　if (val > alpha) {
    　　　alpha = val;
    　　}
    　}
    　return alpha;
    }
```
![算法描述](http://img.blog.csdn.net/20160416162246140)

便于理解的图示，需要注意几点：
* 最开始搜索时，参数如下设置：
  val = AlphaBeta(5, -INFINITY, INFINITY);
  即alpha=-Infinity，beta=Infinity，表示初始本方优势最小，地方的劣势最大；
* 估值函数Evaluate，应该根据走棋方给出对应的估值；
* 对于Val=-0.8点的解释：
  对于第二层的节点（角色B），第三层节点（角色A）
  B首先走了第一种走法，结果A就会选择对B最不利的走法，此时alpha=1
  接着B走了第二种走法，结果当遍历到Val=-0.8时，不管后面的节点是啥，如果B走了这步，A肯定会找到走法使得B的估值<=0.8,所以对于B，果断忽略该分支，这便是剪枝了。

[参考网站](http://www.xqbase.com/computer/search_alphabeta.htm)
